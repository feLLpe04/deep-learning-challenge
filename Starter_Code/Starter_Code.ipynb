{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Import pandas and read the charity_data.csv from the provided cloud URL.\n",
    "import pandas as pd\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "#  YOUR CODE GOES HERE\n",
    "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFFILIATION</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USE_CASE</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATUS</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASK_AMT</th>\n",
       "      <td>8747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Unique Values\n",
       "APPLICATION_TYPE                   17\n",
       "AFFILIATION                         6\n",
       "CLASSIFICATION                     71\n",
       "USE_CASE                            5\n",
       "ORGANIZATION                        4\n",
       "STATUS                              2\n",
       "INCOME_AMT                          9\n",
       "SPECIAL_CONSIDERATIONS              2\n",
       "ASK_AMT                          8747\n",
       "IS_SUCCESSFUL                       2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "#  YOUR CODE GOES HERE\n",
    "unique_values = application_df.nunique()\n",
    "\n",
    "#Display the number of unique values for each column\n",
    "unique_values_df = pd.DataFrame(unique_values, columns=[\"Unique Values\"])\n",
    "\n",
    "#printing the unique values\n",
    "display(unique_values_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\" \n",
    "#  YOUR CODE GOES HERE\n",
    "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
    "#Printing Result \n",
    "display(application_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "#  YOUR CODE GOES HERE\n",
    "# Identify rare application types (e.g., those with fewer than 500 occurrences)\n",
    "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
    "application_types_to_replace = application_type_counts[application_type_counts < 500].index.tolist()\n",
    "\n",
    "# Replace them with \"Other\"\n",
    "application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(application_types_to_replace, \"Other\")\n",
    "\n",
    "# Verify results\n",
    "application_df['APPLICATION_TYPE'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
    "#  YOUR CODE GOES HERE\n",
    "# Identify rare classifications (e.g., those with fewer than 100 occurrences)\n",
    "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
    "classifications_to_replace = classification_counts[classification_counts < 100].index.tolist()\n",
    "\n",
    "# Replace them with \"Other\"\n",
    "application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(classifications_to_replace, \"Other\")\n",
    "\n",
    "# Verify results\n",
    "application_df['CLASSIFICATION'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "#  YOUR CODE GOES HERE\n",
    "classification_counts[classification_counts > 1]\n",
    "\n",
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "#  YOUR CODE GOES HERE\n",
    "classifications_to_replace = classification_counts[classification_counts < 1].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "#  YOUR CODE GOES HERE\n",
    "\n",
    "# Identify rare classifications (e.g., those with fewer than 100 occurrences)\n",
    "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
    "classifications_to_replace = classification_counts[classification_counts < 100].index.tolist()\n",
    "\n",
    "# Replace them with \"Other\"\n",
    "application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(classifications_to_replace, \"Other\")\n",
    "\n",
    "# Verify results\n",
    "application_df['CLASSIFICATION'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0       1     5000              1                  True                 False   \n",
       "1       1   108590              1                 False                 False   \n",
       "2       1     5000              0                 False                 False   \n",
       "3       1     6692              1                 False                 False   \n",
       "4       1   142590              1                 False                 False   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                False                False                False   \n",
       "1                 True                False                False   \n",
       "2                False                False                 True   \n",
       "3                 True                False                False   \n",
       "4                 True                False                False   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  ORGANIZATION_Trust  \\\n",
       "0                False                False  ...               False   \n",
       "1                False                False  ...               False   \n",
       "2                False                False  ...               False   \n",
       "3                False                False  ...                True   \n",
       "4                False                False  ...                True   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0              False                   False                     False   \n",
       "1               True                   False                     False   \n",
       "2              False                   False                     False   \n",
       "3              False                    True                     False   \n",
       "4              False                   False                      True   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0               False             False                   False   \n",
       "1               False             False                   False   \n",
       "2               False             False                   False   \n",
       "3               False             False                   False   \n",
       "4               False             False                   False   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_Y  \n",
       "0            False              False                     False  \n",
       "1            False              False                     False  \n",
       "2            False              False                     False  \n",
       "3            False              False                     False  \n",
       "4            False              False                     False  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "#  YOUR CODE GOES HERE\n",
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "# Convert categorical data to numeric with one-hot encoding\n",
    "application_df = pd.get_dummies(application_df, drop_first=True)\n",
    "\n",
    "# Verify transformation\n",
    "application_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27439, 42), (6860, 42), (27439,), (6860,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "#  YOUR CODE GOES HERE\n",
    "\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "X = application_df.drop(columns=['IS_SUCCESSFUL'])  # Features\n",
    "y = application_df['IS_SUCCESSFUL']  # Target\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shape of the datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.01350021, -0.03115182, -0.12527962, -0.17944646,  0.51907853,\n",
       "         -0.21911203, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199,  0.92492753, -0.02896422, -0.01207473, -0.01909392,\n",
       "          2.48241006, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781,  0.4707167 , -0.44526614,\n",
       "         -0.11991987, -0.03416994,  0.67719293, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705],\n",
       "        [ 0.01350021, -0.03115182, -0.12527962, -0.17944646,  0.51907853,\n",
       "         -0.21911203, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199,  0.92492753, -0.02896422, -0.01207473, -0.01909392,\n",
       "         -0.40283433, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781,  0.4707167 , -0.44526614,\n",
       "         -0.11991987, -0.03416994,  0.67719293, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705],\n",
       "        [ 0.01350021, -0.03115182, -0.12527962, -0.17944646,  0.51907853,\n",
       "         -0.21911203, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199, -1.08116578, -0.02896422, -0.01207473, -0.01909392,\n",
       "         -0.40283433, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781,  0.4707167 , -0.44526614,\n",
       "         -0.11991987, -0.03416994,  0.67719293, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705],\n",
       "        [ 0.01350021, -0.03115182, -0.12527962, -0.17944646,  0.51907853,\n",
       "         -0.21911203, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199,  0.92492753, -0.02896422, -0.01207473, -0.01909392,\n",
       "         -0.40283433, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781,  0.4707167 , -0.44526614,\n",
       "         -0.11991987, -0.03416994,  0.67719293, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705],\n",
       "        [ 0.01350021, -0.03115182, -0.12527962, -0.17944646, -1.92649079,\n",
       "          4.56387531, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199, -1.08116578, -0.02896422, -0.01207473, -0.01909392,\n",
       "         -0.40283433, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177,  4.0729722 , -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781, -2.12442005,  2.24584786,\n",
       "         -0.11991987, -0.03416994, -1.47668406, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705]]),\n",
       " array([[ 0.01350021, -0.03067262, -0.12527962, -0.17944646,  0.51907853,\n",
       "         -0.21911203, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199,  0.92492753, -0.02896422, -0.01207473, -0.01909392,\n",
       "         -0.40283433, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781,  0.4707167 , -0.44526614,\n",
       "         -0.11991987, -0.03416994,  0.67719293, -0.14887949, -0.1270683 ,\n",
       "          3.05912543, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705],\n",
       "        [ 0.01350021, -0.03115182, -0.12527962, -0.17944646,  0.51907853,\n",
       "         -0.21911203, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199, -1.08116578, -0.02896422, -0.01207473, -0.01909392,\n",
       "         -0.40283433, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781,  0.4707167 , -0.44526614,\n",
       "         -0.11991987, -0.03416994,  0.67719293, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705],\n",
       "        [ 0.01350021, -0.03115182, -0.12527962, -0.17944646,  0.51907853,\n",
       "         -0.21911203, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199, -1.08116578, -0.02896422, -0.01207473, -0.01909392,\n",
       "          2.48241006, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781,  0.4707167 , -0.44526614,\n",
       "         -0.11991987, -0.03416994, -1.47668406, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705],\n",
       "        [ 0.01350021, -0.03115182, -0.12527962, -0.17944646,  0.51907853,\n",
       "         -0.21911203, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199, -1.08116578, -0.02896422, -0.01207473, -0.01909392,\n",
       "          2.48241006, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781,  0.4707167 , -0.44526614,\n",
       "         -0.11991987, -0.03416994, -1.47668406, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705],\n",
       "        [ 0.01350021, -0.03115182, -0.12527962, -0.17944646, -1.92649079,\n",
       "          4.56387531, -0.18792753, -0.19092108, -0.14669078, -0.14746666,\n",
       "         -0.04399199,  0.92492753, -0.02896422, -0.01207473, -0.01909392,\n",
       "         -0.40283433, -0.05800148, -0.09133405, -0.46452418, -0.24401553,\n",
       "         -0.05200177, -0.24552095, -0.07561644, -0.0540748 , -0.1525469 ,\n",
       "         -0.14115038, -0.06599836, -0.00853781, -2.12442005,  2.24584786,\n",
       "         -0.11991987, -0.03416994,  0.67719293, -0.14887949, -0.1270683 ,\n",
       "         -0.32689081, -0.08372388, -0.17037257, -0.35069127, -0.06459105,\n",
       "         -0.07135527, -0.02832705]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Verify transformation\n",
    "X_train_scaled[:5], X_test_scaled[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m3,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,901</span> (23.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,901\u001b[0m (23.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,901</span> (23.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,901\u001b[0m (23.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "#  YOUR CODE GOES HERE\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=X_train_scaled.shape[1]))\n",
    "\n",
    "#Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=30, activation=\"relu\"))\n",
    "\n",
    "#Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "#Check the structure of the model\n",
    "nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6873 - loss: 0.5976 - val_accuracy: 0.7216 - val_loss: 0.5609\n",
      "Epoch 2/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7295 - loss: 0.5503 - val_accuracy: 0.7232 - val_loss: 0.5596\n",
      "Epoch 3/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7279 - loss: 0.5540 - val_accuracy: 0.7259 - val_loss: 0.5559\n",
      "Epoch 4/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7306 - loss: 0.5480 - val_accuracy: 0.7214 - val_loss: 0.5562\n",
      "Epoch 5/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7332 - loss: 0.5450 - val_accuracy: 0.7292 - val_loss: 0.5531\n",
      "Epoch 6/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7334 - loss: 0.5463 - val_accuracy: 0.7267 - val_loss: 0.5551\n",
      "Epoch 7/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7334 - loss: 0.5438 - val_accuracy: 0.7270 - val_loss: 0.5530\n",
      "Epoch 8/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.5410 - val_accuracy: 0.7277 - val_loss: 0.5546\n",
      "Epoch 9/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7359 - loss: 0.5428 - val_accuracy: 0.7287 - val_loss: 0.5533\n",
      "Epoch 10/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7345 - loss: 0.5435 - val_accuracy: 0.7265 - val_loss: 0.5555\n",
      "Epoch 11/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7323 - loss: 0.5480 - val_accuracy: 0.7271 - val_loss: 0.5554\n",
      "Epoch 12/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5404 - val_accuracy: 0.7292 - val_loss: 0.5518\n",
      "Epoch 13/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.5384 - val_accuracy: 0.7302 - val_loss: 0.5541\n",
      "Epoch 14/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5383 - val_accuracy: 0.7294 - val_loss: 0.5534\n",
      "Epoch 15/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7355 - loss: 0.5411 - val_accuracy: 0.7265 - val_loss: 0.5547\n",
      "Epoch 16/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7349 - loss: 0.5407 - val_accuracy: 0.7278 - val_loss: 0.5553\n",
      "Epoch 17/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5415 - val_accuracy: 0.7262 - val_loss: 0.5532\n",
      "Epoch 18/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5392 - val_accuracy: 0.7261 - val_loss: 0.5519\n",
      "Epoch 19/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5387 - val_accuracy: 0.7296 - val_loss: 0.5511\n",
      "Epoch 20/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7347 - loss: 0.5385 - val_accuracy: 0.7273 - val_loss: 0.5545\n",
      "Epoch 21/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7318 - loss: 0.5478 - val_accuracy: 0.7296 - val_loss: 0.5529\n",
      "Epoch 22/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5391 - val_accuracy: 0.7281 - val_loss: 0.5532\n",
      "Epoch 23/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7364 - loss: 0.5401 - val_accuracy: 0.7271 - val_loss: 0.5520\n",
      "Epoch 24/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7384 - loss: 0.5387 - val_accuracy: 0.7309 - val_loss: 0.5520\n",
      "Epoch 25/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7369 - loss: 0.5391 - val_accuracy: 0.7262 - val_loss: 0.5534\n",
      "Epoch 26/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7394 - loss: 0.5370 - val_accuracy: 0.7243 - val_loss: 0.5548\n",
      "Epoch 27/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5371 - val_accuracy: 0.7294 - val_loss: 0.5535\n",
      "Epoch 28/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.5346 - val_accuracy: 0.7271 - val_loss: 0.5536\n",
      "Epoch 29/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5369 - val_accuracy: 0.7308 - val_loss: 0.5557\n",
      "Epoch 30/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7347 - loss: 0.5390 - val_accuracy: 0.7268 - val_loss: 0.5546\n",
      "Epoch 31/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7343 - loss: 0.5384 - val_accuracy: 0.7280 - val_loss: 0.5529\n",
      "Epoch 32/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7393 - loss: 0.5400 - val_accuracy: 0.7294 - val_loss: 0.5532\n",
      "Epoch 33/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.5350 - val_accuracy: 0.7286 - val_loss: 0.5552\n",
      "Epoch 34/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7417 - loss: 0.5328 - val_accuracy: 0.7268 - val_loss: 0.5557\n",
      "Epoch 35/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7416 - loss: 0.5356 - val_accuracy: 0.7302 - val_loss: 0.5550\n",
      "Epoch 36/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5332 - val_accuracy: 0.7308 - val_loss: 0.5539\n",
      "Epoch 37/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7393 - loss: 0.5354 - val_accuracy: 0.7283 - val_loss: 0.5528\n",
      "Epoch 38/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.5375 - val_accuracy: 0.7290 - val_loss: 0.5543\n",
      "Epoch 39/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5363 - val_accuracy: 0.7302 - val_loss: 0.5548\n",
      "Epoch 40/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7402 - loss: 0.5370 - val_accuracy: 0.7308 - val_loss: 0.5549\n",
      "Epoch 41/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5310 - val_accuracy: 0.7302 - val_loss: 0.5544\n",
      "Epoch 42/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7353 - loss: 0.5400 - val_accuracy: 0.7273 - val_loss: 0.5545\n",
      "Epoch 43/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7400 - loss: 0.5326 - val_accuracy: 0.7271 - val_loss: 0.5570\n",
      "Epoch 44/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7360 - loss: 0.5393 - val_accuracy: 0.7289 - val_loss: 0.5561\n",
      "Epoch 45/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7409 - loss: 0.5328 - val_accuracy: 0.7296 - val_loss: 0.5549\n",
      "Epoch 46/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.5359 - val_accuracy: 0.7276 - val_loss: 0.5565\n",
      "Epoch 47/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5324 - val_accuracy: 0.7267 - val_loss: 0.5571\n",
      "Epoch 48/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7367 - loss: 0.5354 - val_accuracy: 0.7296 - val_loss: 0.5559\n",
      "Epoch 49/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7406 - loss: 0.5316 - val_accuracy: 0.7277 - val_loss: 0.5561\n",
      "Epoch 50/50\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7368 - loss: 0.5376 - val_accuracy: 0.7294 - val_loss: 0.5563\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "#  YOUR CODE GOES HERE\n",
    "#Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Train the model\n",
    "history = nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - 2ms/step - accuracy: 0.7294 - loss: 0.5563\n",
      "Loss: 0.5563, Accuracy: 0.7294\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Evaluate the model's performance\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Loss: {model_loss:.4f}, Accuracy: {model_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - 807us/step - accuracy: 0.7294 - loss: 0.5563\n",
      "Loss: 0.5563365817070007, Accuracy: 0.7294460535049438\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,481</span> (205.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,481\u001b[0m (205.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,353</span> (204.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,353\u001b[0m (204.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the model - deep neural net\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#First hidden layer - Increased neurons\n",
    "nn.add(tf.keras.layers.Dense(units=256, activation=\"relu\", input_dim=X_train_scaled.shape[1]))\n",
    "\n",
    "#Second hidden layer - Increased neurons\n",
    "nn.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "\n",
    "#Third hidden layer - Added another layer\n",
    "nn.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "\n",
    "#Fourth hidden layer - Apply dropout to reduce overfitting\n",
    "nn.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "#Fifth hidden layer - Batch normalization to stabilize learning\n",
    "nn.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if compiled \n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adamax\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6889 - loss: 0.6290 - val_accuracy: 0.7239 - val_loss: 0.5728 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7160 - loss: 0.5804 - val_accuracy: 0.7257 - val_loss: 0.5684 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7235 - loss: 0.5679 - val_accuracy: 0.7140 - val_loss: 0.5691 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7227 - loss: 0.5660 - val_accuracy: 0.7245 - val_loss: 0.5614 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7291 - loss: 0.5599 - val_accuracy: 0.7261 - val_loss: 0.5572 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7247 - loss: 0.5609 - val_accuracy: 0.7248 - val_loss: 0.5576 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7291 - loss: 0.5560 - val_accuracy: 0.7271 - val_loss: 0.5544 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7312 - loss: 0.5520 - val_accuracy: 0.7286 - val_loss: 0.5571 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7338 - loss: 0.5501 - val_accuracy: 0.7284 - val_loss: 0.5516 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7337 - loss: 0.5518 - val_accuracy: 0.7297 - val_loss: 0.5531 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7307 - loss: 0.5549 - val_accuracy: 0.7257 - val_loss: 0.5559 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7291 - loss: 0.5555 - val_accuracy: 0.7286 - val_loss: 0.5536 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.5474 - val_accuracy: 0.7271 - val_loss: 0.5540 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7346 - loss: 0.5490 - val_accuracy: 0.7259 - val_loss: 0.5534 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7287 - loss: 0.5507 - val_accuracy: 0.7284 - val_loss: 0.5526 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5472 - val_accuracy: 0.7284 - val_loss: 0.5533 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7343 - loss: 0.5448 - val_accuracy: 0.7303 - val_loss: 0.5527 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7354 - loss: 0.5481 - val_accuracy: 0.7292 - val_loss: 0.5526 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7359 - loss: 0.5478 - val_accuracy: 0.7312 - val_loss: 0.5529 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "#Adding early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "#Reducing learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "#Fit the model with the new epochs and callbacks\n",
    "history = nn.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - 914us/step - accuracy: 0.7284 - loss: 0.5516\n",
      "Final Loss: 0.5516, Final Accuracy: 0.7284\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the models final performance\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "#print results\n",
    "print(f\"Final Loss: {model_loss:.4f}, Final Accuracy: {model_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW IMPROVEMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "\u001b[1m402/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6144 - loss: 4.6316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6168 - loss: 4.5239 - val_accuracy: 0.6971 - val_loss: 1.1501 - learning_rate: 0.0010\n",
      "Epoch 2/350\n",
      "\u001b[1m417/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.9579"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.9544 - val_accuracy: 0.7222 - val_loss: 0.6880 - learning_rate: 0.0010\n",
      "Epoch 3/350\n",
      "\u001b[1m417/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.6642"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.6639 - val_accuracy: 0.7223 - val_loss: 0.6285 - learning_rate: 0.0010\n",
      "Epoch 4/350\n",
      "\u001b[1m421/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.6342 - val_accuracy: 0.7242 - val_loss: 0.6269 - learning_rate: 0.0010\n",
      "Epoch 5/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6333 - val_accuracy: 0.7222 - val_loss: 0.6377 - learning_rate: 0.0010\n",
      "Epoch 6/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.6375 - val_accuracy: 0.7185 - val_loss: 0.6313 - learning_rate: 0.0010\n",
      "Epoch 7/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.6393 - val_accuracy: 0.7023 - val_loss: 0.6319 - learning_rate: 0.0010\n",
      "Epoch 8/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7185 - loss: 0.6315 - val_accuracy: 0.7190 - val_loss: 0.6316 - learning_rate: 0.0010\n",
      "Epoch 9/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.6334 - val_accuracy: 0.7192 - val_loss: 0.6255 - learning_rate: 0.0010\n",
      "Epoch 10/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.6283 - val_accuracy: 0.7236 - val_loss: 0.6268 - learning_rate: 0.0010\n",
      "Epoch 11/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7221 - loss: 0.6305 - val_accuracy: 0.7223 - val_loss: 0.6289 - learning_rate: 0.0010\n",
      "Epoch 12/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.6386 - val_accuracy: 0.7157 - val_loss: 0.6426 - learning_rate: 0.0010\n",
      "Epoch 13/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.6385 - val_accuracy: 0.7124 - val_loss: 0.6350 - learning_rate: 0.0010\n",
      "Epoch 14/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.6362 - val_accuracy: 0.7223 - val_loss: 0.6340 - learning_rate: 0.0010\n",
      "Epoch 15/350\n",
      "\u001b[1m425/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.6353"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.6353 - val_accuracy: 0.7243 - val_loss: 0.6280 - learning_rate: 0.0010\n",
      "Epoch 16/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.6380 - val_accuracy: 0.7219 - val_loss: 0.6270 - learning_rate: 0.0010\n",
      "Epoch 17/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.6323 - val_accuracy: 0.7128 - val_loss: 0.6292 - learning_rate: 0.0010\n",
      "Epoch 18/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.6199 - val_accuracy: 0.7219 - val_loss: 0.6020 - learning_rate: 5.0000e-04\n",
      "Epoch 19/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.6036 - val_accuracy: 0.7182 - val_loss: 0.5988 - learning_rate: 5.0000e-04\n",
      "Epoch 20/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.6039 - val_accuracy: 0.7207 - val_loss: 0.6008 - learning_rate: 5.0000e-04\n",
      "Epoch 21/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.6008 - val_accuracy: 0.7198 - val_loss: 0.5987 - learning_rate: 5.0000e-04\n",
      "Epoch 22/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.6042 - val_accuracy: 0.7208 - val_loss: 0.6009 - learning_rate: 5.0000e-04\n",
      "Epoch 23/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.6043 - val_accuracy: 0.7238 - val_loss: 0.5997 - learning_rate: 5.0000e-04\n",
      "Epoch 24/350\n",
      "\u001b[1m427/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.6052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.6052 - val_accuracy: 0.7265 - val_loss: 0.5967 - learning_rate: 5.0000e-04\n",
      "Epoch 25/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5965 - val_accuracy: 0.7243 - val_loss: 0.5966 - learning_rate: 5.0000e-04\n",
      "Epoch 26/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.6062 - val_accuracy: 0.7172 - val_loss: 0.5992 - learning_rate: 5.0000e-04\n",
      "Epoch 27/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.6018 - val_accuracy: 0.7265 - val_loss: 0.5973 - learning_rate: 5.0000e-04\n",
      "Epoch 28/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.6025 - val_accuracy: 0.7211 - val_loss: 0.5957 - learning_rate: 5.0000e-04\n",
      "Epoch 29/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.6075 - val_accuracy: 0.7172 - val_loss: 0.5981 - learning_rate: 5.0000e-04\n",
      "Epoch 30/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5999 - val_accuracy: 0.7210 - val_loss: 0.5965 - learning_rate: 5.0000e-04\n",
      "Epoch 31/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.6002 - val_accuracy: 0.7095 - val_loss: 0.6019 - learning_rate: 5.0000e-04\n",
      "Epoch 32/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.6001 - val_accuracy: 0.7214 - val_loss: 0.6009 - learning_rate: 5.0000e-04\n",
      "Epoch 33/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.6045 - val_accuracy: 0.7184 - val_loss: 0.5978 - learning_rate: 5.0000e-04\n",
      "Epoch 34/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.6011 - val_accuracy: 0.7200 - val_loss: 0.5962 - learning_rate: 5.0000e-04\n",
      "Epoch 35/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5993 - val_accuracy: 0.7216 - val_loss: 0.5969 - learning_rate: 5.0000e-04\n",
      "Epoch 36/350\n",
      "\u001b[1m409/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.6025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.6025 - val_accuracy: 0.7276 - val_loss: 0.5981 - learning_rate: 5.0000e-04\n",
      "Epoch 37/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5970 - val_accuracy: 0.7248 - val_loss: 0.5844 - learning_rate: 2.5000e-04\n",
      "Epoch 38/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5899 - val_accuracy: 0.7235 - val_loss: 0.5831 - learning_rate: 2.5000e-04\n",
      "Epoch 39/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5811 - val_accuracy: 0.7224 - val_loss: 0.5842 - learning_rate: 2.5000e-04\n",
      "Epoch 40/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.5878 - val_accuracy: 0.7220 - val_loss: 0.5830 - learning_rate: 2.5000e-04\n",
      "Epoch 41/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5839 - val_accuracy: 0.7203 - val_loss: 0.5819 - learning_rate: 2.5000e-04\n",
      "Epoch 42/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5838 - val_accuracy: 0.7238 - val_loss: 0.5801 - learning_rate: 2.5000e-04\n",
      "Epoch 43/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5866 - val_accuracy: 0.7242 - val_loss: 0.5800 - learning_rate: 2.5000e-04\n",
      "Epoch 44/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.5834 - val_accuracy: 0.7217 - val_loss: 0.5821 - learning_rate: 2.5000e-04\n",
      "Epoch 45/350\n",
      "\u001b[1m422/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5810 - val_accuracy: 0.7280 - val_loss: 0.5798 - learning_rate: 2.5000e-04\n",
      "Epoch 46/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.5865 - val_accuracy: 0.7246 - val_loss: 0.5782 - learning_rate: 2.5000e-04\n",
      "Epoch 47/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.5879 - val_accuracy: 0.7224 - val_loss: 0.5805 - learning_rate: 2.5000e-04\n",
      "Epoch 48/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.5851 - val_accuracy: 0.7264 - val_loss: 0.5778 - learning_rate: 2.5000e-04\n",
      "Epoch 49/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.5861 - val_accuracy: 0.7214 - val_loss: 0.5790 - learning_rate: 2.5000e-04\n",
      "Epoch 50/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.5858 - val_accuracy: 0.7241 - val_loss: 0.5775 - learning_rate: 2.5000e-04\n",
      "Epoch 51/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5881 - val_accuracy: 0.7235 - val_loss: 0.5787 - learning_rate: 2.5000e-04\n",
      "Epoch 52/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5859 - val_accuracy: 0.7243 - val_loss: 0.5798 - learning_rate: 2.5000e-04\n",
      "Epoch 53/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.5910 - val_accuracy: 0.7252 - val_loss: 0.5802 - learning_rate: 2.5000e-04\n",
      "Epoch 54/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.5825 - val_accuracy: 0.7245 - val_loss: 0.5792 - learning_rate: 2.5000e-04\n",
      "Epoch 55/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5809 - val_accuracy: 0.7194 - val_loss: 0.5813 - learning_rate: 2.5000e-04\n",
      "Epoch 56/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5868 - val_accuracy: 0.7226 - val_loss: 0.5797 - learning_rate: 2.5000e-04\n",
      "Epoch 57/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5818 - val_accuracy: 0.7243 - val_loss: 0.5798 - learning_rate: 2.5000e-04\n",
      "Epoch 58/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5813 - val_accuracy: 0.7280 - val_loss: 0.5791 - learning_rate: 2.5000e-04\n",
      "Epoch 59/350\n",
      "\u001b[1m427/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.5792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.5792 - val_accuracy: 0.7284 - val_loss: 0.5746 - learning_rate: 1.2500e-04\n",
      "Epoch 60/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5757 - val_accuracy: 0.7220 - val_loss: 0.5732 - learning_rate: 1.2500e-04\n",
      "Epoch 61/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5764 - val_accuracy: 0.7232 - val_loss: 0.5712 - learning_rate: 1.2500e-04\n",
      "Epoch 62/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.5741 - val_accuracy: 0.7251 - val_loss: 0.5714 - learning_rate: 1.2500e-04\n",
      "Epoch 63/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5739 - val_accuracy: 0.7235 - val_loss: 0.5713 - learning_rate: 1.2500e-04\n",
      "Epoch 64/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5733 - val_accuracy: 0.7232 - val_loss: 0.5700 - learning_rate: 1.2500e-04\n",
      "Epoch 65/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5698 - val_accuracy: 0.7278 - val_loss: 0.5710 - learning_rate: 1.2500e-04\n",
      "Epoch 66/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.5746 - val_accuracy: 0.7254 - val_loss: 0.5691 - learning_rate: 1.2500e-04\n",
      "Epoch 67/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5713 - val_accuracy: 0.7254 - val_loss: 0.5699 - learning_rate: 1.2500e-04\n",
      "Epoch 68/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5734 - val_accuracy: 0.7274 - val_loss: 0.5694 - learning_rate: 1.2500e-04\n",
      "Epoch 69/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5794 - val_accuracy: 0.7224 - val_loss: 0.5701 - learning_rate: 1.2500e-04\n",
      "Epoch 70/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5729 - val_accuracy: 0.7273 - val_loss: 0.5694 - learning_rate: 1.2500e-04\n",
      "Epoch 71/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5713 - val_accuracy: 0.7261 - val_loss: 0.5693 - learning_rate: 1.2500e-04\n",
      "Epoch 72/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.5739 - val_accuracy: 0.7249 - val_loss: 0.5696 - learning_rate: 1.2500e-04\n",
      "Epoch 73/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5717 - val_accuracy: 0.7265 - val_loss: 0.5696 - learning_rate: 1.2500e-04\n",
      "Epoch 74/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.5709 - val_accuracy: 0.7254 - val_loss: 0.5689 - learning_rate: 1.2500e-04\n",
      "Epoch 75/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5726 - val_accuracy: 0.7258 - val_loss: 0.5682 - learning_rate: 1.2500e-04\n",
      "Epoch 76/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5686 - val_accuracy: 0.7243 - val_loss: 0.5707 - learning_rate: 1.2500e-04\n",
      "Epoch 77/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5707 - val_accuracy: 0.7257 - val_loss: 0.5704 - learning_rate: 1.2500e-04\n",
      "Epoch 78/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5668 - val_accuracy: 0.7252 - val_loss: 0.5712 - learning_rate: 1.2500e-04\n",
      "Epoch 79/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5712 - val_accuracy: 0.7238 - val_loss: 0.5690 - learning_rate: 1.2500e-04\n",
      "Epoch 80/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.5714 - val_accuracy: 0.7251 - val_loss: 0.5701 - learning_rate: 1.2500e-04\n",
      "Epoch 81/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.5729 - val_accuracy: 0.7239 - val_loss: 0.5692 - learning_rate: 1.2500e-04\n",
      "Epoch 82/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5686 - val_accuracy: 0.7251 - val_loss: 0.5689 - learning_rate: 1.2500e-04\n",
      "Epoch 83/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5715 - val_accuracy: 0.7238 - val_loss: 0.5693 - learning_rate: 1.2500e-04\n",
      "Epoch 84/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5757 - val_accuracy: 0.7226 - val_loss: 0.5679 - learning_rate: 6.2500e-05\n",
      "Epoch 85/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5665 - val_accuracy: 0.7232 - val_loss: 0.5672 - learning_rate: 6.2500e-05\n",
      "Epoch 86/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.5733 - val_accuracy: 0.7252 - val_loss: 0.5659 - learning_rate: 6.2500e-05\n",
      "Epoch 87/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5668 - val_accuracy: 0.7227 - val_loss: 0.5650 - learning_rate: 6.2500e-05\n",
      "Epoch 88/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5667 - val_accuracy: 0.7243 - val_loss: 0.5658 - learning_rate: 6.2500e-05\n",
      "Epoch 89/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5629 - val_accuracy: 0.7245 - val_loss: 0.5656 - learning_rate: 6.2500e-05\n",
      "Epoch 90/350\n",
      "\u001b[1m404/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.5659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.5660 - val_accuracy: 0.7287 - val_loss: 0.5643 - learning_rate: 6.2500e-05\n",
      "Epoch 91/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.5673 - val_accuracy: 0.7265 - val_loss: 0.5639 - learning_rate: 6.2500e-05\n",
      "Epoch 92/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5718 - val_accuracy: 0.7254 - val_loss: 0.5643 - learning_rate: 6.2500e-05\n",
      "Epoch 93/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5641 - val_accuracy: 0.7270 - val_loss: 0.5648 - learning_rate: 6.2500e-05\n",
      "Epoch 94/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5660 - val_accuracy: 0.7289 - val_loss: 0.5650 - learning_rate: 6.2500e-05\n",
      "Epoch 95/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5686 - val_accuracy: 0.7257 - val_loss: 0.5642 - learning_rate: 6.2500e-05\n",
      "Epoch 96/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.5651 - val_accuracy: 0.7270 - val_loss: 0.5640 - learning_rate: 6.2500e-05\n",
      "Epoch 97/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5699 - val_accuracy: 0.7271 - val_loss: 0.5636 - learning_rate: 6.2500e-05\n",
      "Epoch 98/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5628 - val_accuracy: 0.7235 - val_loss: 0.5647 - learning_rate: 6.2500e-05\n",
      "Epoch 99/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5698 - val_accuracy: 0.7246 - val_loss: 0.5644 - learning_rate: 6.2500e-05\n",
      "Epoch 100/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.5682 - val_accuracy: 0.7248 - val_loss: 0.5648 - learning_rate: 6.2500e-05\n",
      "Epoch 101/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5626 - val_accuracy: 0.7236 - val_loss: 0.5645 - learning_rate: 6.2500e-05\n",
      "Epoch 102/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5651 - val_accuracy: 0.7226 - val_loss: 0.5649 - learning_rate: 6.2500e-05\n",
      "Epoch 103/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5649 - val_accuracy: 0.7235 - val_loss: 0.5645 - learning_rate: 6.2500e-05\n",
      "Epoch 104/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5623 - val_accuracy: 0.7254 - val_loss: 0.5639 - learning_rate: 6.2500e-05\n",
      "Epoch 105/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.5660 - val_accuracy: 0.7235 - val_loss: 0.5634 - learning_rate: 6.2500e-05\n",
      "Epoch 106/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5635 - val_accuracy: 0.7233 - val_loss: 0.5634 - learning_rate: 6.2500e-05\n",
      "Epoch 107/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5618 - val_accuracy: 0.7261 - val_loss: 0.5630 - learning_rate: 6.2500e-05\n",
      "Epoch 108/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5700 - val_accuracy: 0.7262 - val_loss: 0.5647 - learning_rate: 6.2500e-05\n",
      "Epoch 109/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.5691 - val_accuracy: 0.7248 - val_loss: 0.5640 - learning_rate: 6.2500e-05\n",
      "Epoch 110/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.5685 - val_accuracy: 0.7222 - val_loss: 0.5636 - learning_rate: 6.2500e-05\n",
      "Epoch 111/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.5659 - val_accuracy: 0.7236 - val_loss: 0.5642 - learning_rate: 6.2500e-05\n",
      "Epoch 112/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5645 - val_accuracy: 0.7238 - val_loss: 0.5623 - learning_rate: 6.2500e-05\n",
      "Epoch 113/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5673 - val_accuracy: 0.7235 - val_loss: 0.5642 - learning_rate: 6.2500e-05\n",
      "Epoch 114/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.5651 - val_accuracy: 0.7242 - val_loss: 0.5631 - learning_rate: 6.2500e-05\n",
      "Epoch 115/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.5644 - val_accuracy: 0.7268 - val_loss: 0.5631 - learning_rate: 6.2500e-05\n",
      "Epoch 116/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5649 - val_accuracy: 0.7238 - val_loss: 0.5628 - learning_rate: 6.2500e-05\n",
      "Epoch 117/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5667 - val_accuracy: 0.7236 - val_loss: 0.5627 - learning_rate: 6.2500e-05\n",
      "Epoch 118/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5648 - val_accuracy: 0.7252 - val_loss: 0.5640 - learning_rate: 6.2500e-05\n",
      "Epoch 119/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5656 - val_accuracy: 0.7254 - val_loss: 0.5631 - learning_rate: 6.2500e-05\n",
      "Epoch 120/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5719 - val_accuracy: 0.7254 - val_loss: 0.5622 - learning_rate: 6.2500e-05\n",
      "Epoch 121/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5685 - val_accuracy: 0.7254 - val_loss: 0.5628 - learning_rate: 6.2500e-05\n",
      "Epoch 122/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5663 - val_accuracy: 0.7258 - val_loss: 0.5627 - learning_rate: 6.2500e-05\n",
      "Epoch 123/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.5723 - val_accuracy: 0.7255 - val_loss: 0.5633 - learning_rate: 6.2500e-05\n",
      "Epoch 124/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.5665 - val_accuracy: 0.7261 - val_loss: 0.5634 - learning_rate: 6.2500e-05\n",
      "Epoch 125/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5658 - val_accuracy: 0.7261 - val_loss: 0.5631 - learning_rate: 6.2500e-05\n",
      "Epoch 126/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5607 - val_accuracy: 0.7251 - val_loss: 0.5635 - learning_rate: 6.2500e-05\n",
      "Epoch 127/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.5670 - val_accuracy: 0.7270 - val_loss: 0.5635 - learning_rate: 6.2500e-05\n",
      "Epoch 128/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7292 - loss: 0.5649 - val_accuracy: 0.7249 - val_loss: 0.5634 - learning_rate: 6.2500e-05\n",
      "Epoch 129/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.5654 - val_accuracy: 0.7235 - val_loss: 0.5623 - learning_rate: 3.1250e-05\n",
      "Epoch 130/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5688 - val_accuracy: 0.7239 - val_loss: 0.5620 - learning_rate: 3.1250e-05\n",
      "Epoch 131/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5631 - val_accuracy: 0.7235 - val_loss: 0.5616 - learning_rate: 3.1250e-05\n",
      "Epoch 132/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.5644 - val_accuracy: 0.7242 - val_loss: 0.5618 - learning_rate: 3.1250e-05\n",
      "Epoch 133/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5610 - val_accuracy: 0.7236 - val_loss: 0.5616 - learning_rate: 3.1250e-05\n",
      "Epoch 134/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5627 - val_accuracy: 0.7236 - val_loss: 0.5614 - learning_rate: 3.1250e-05\n",
      "Epoch 135/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5615 - val_accuracy: 0.7248 - val_loss: 0.5606 - learning_rate: 3.1250e-05\n",
      "Epoch 136/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5628 - val_accuracy: 0.7241 - val_loss: 0.5607 - learning_rate: 3.1250e-05\n",
      "Epoch 137/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5605 - val_accuracy: 0.7251 - val_loss: 0.5608 - learning_rate: 3.1250e-05\n",
      "Epoch 138/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5583 - val_accuracy: 0.7243 - val_loss: 0.5606 - learning_rate: 3.1250e-05\n",
      "Epoch 139/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.5684 - val_accuracy: 0.7233 - val_loss: 0.5609 - learning_rate: 3.1250e-05\n",
      "Epoch 140/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.5583 - val_accuracy: 0.7232 - val_loss: 0.5602 - learning_rate: 3.1250e-05\n",
      "Epoch 141/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.5626 - val_accuracy: 0.7230 - val_loss: 0.5607 - learning_rate: 3.1250e-05\n",
      "Epoch 142/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5629 - val_accuracy: 0.7249 - val_loss: 0.5599 - learning_rate: 3.1250e-05\n",
      "Epoch 143/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5612 - val_accuracy: 0.7259 - val_loss: 0.5604 - learning_rate: 3.1250e-05\n",
      "Epoch 144/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.5588 - val_accuracy: 0.7243 - val_loss: 0.5595 - learning_rate: 3.1250e-05\n",
      "Epoch 145/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.5569 - val_accuracy: 0.7255 - val_loss: 0.5605 - learning_rate: 3.1250e-05\n",
      "Epoch 146/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5589 - val_accuracy: 0.7236 - val_loss: 0.5605 - learning_rate: 3.1250e-05\n",
      "Epoch 147/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.5644 - val_accuracy: 0.7233 - val_loss: 0.5605 - learning_rate: 3.1250e-05\n",
      "Epoch 148/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5645 - val_accuracy: 0.7246 - val_loss: 0.5604 - learning_rate: 3.1250e-05\n",
      "Epoch 149/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.5645 - val_accuracy: 0.7236 - val_loss: 0.5601 - learning_rate: 3.1250e-05\n",
      "Epoch 150/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.5638 - val_accuracy: 0.7232 - val_loss: 0.5602 - learning_rate: 3.1250e-05\n",
      "Epoch 151/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5565 - val_accuracy: 0.7232 - val_loss: 0.5592 - learning_rate: 3.1250e-05\n",
      "Epoch 152/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.5594 - val_accuracy: 0.7232 - val_loss: 0.5604 - learning_rate: 3.1250e-05\n",
      "Epoch 153/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.5673 - val_accuracy: 0.7235 - val_loss: 0.5598 - learning_rate: 3.1250e-05\n",
      "Epoch 154/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5620 - val_accuracy: 0.7245 - val_loss: 0.5600 - learning_rate: 3.1250e-05\n",
      "Epoch 155/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5578 - val_accuracy: 0.7242 - val_loss: 0.5597 - learning_rate: 3.1250e-05\n",
      "Epoch 156/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.5639 - val_accuracy: 0.7270 - val_loss: 0.5596 - learning_rate: 3.1250e-05\n",
      "Epoch 157/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5648 - val_accuracy: 0.7232 - val_loss: 0.5610 - learning_rate: 3.1250e-05\n",
      "Epoch 158/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5674 - val_accuracy: 0.7233 - val_loss: 0.5596 - learning_rate: 3.1250e-05\n",
      "Epoch 159/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5636 - val_accuracy: 0.7243 - val_loss: 0.5593 - learning_rate: 3.1250e-05\n",
      "Epoch 160/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.5611 - val_accuracy: 0.7241 - val_loss: 0.5594 - learning_rate: 1.5625e-05\n",
      "Epoch 161/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5571 - val_accuracy: 0.7233 - val_loss: 0.5592 - learning_rate: 1.5625e-05\n",
      "Epoch 162/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5584 - val_accuracy: 0.7248 - val_loss: 0.5594 - learning_rate: 1.5625e-05\n",
      "Epoch 163/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5627 - val_accuracy: 0.7233 - val_loss: 0.5592 - learning_rate: 1.5625e-05\n",
      "Epoch 164/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5607 - val_accuracy: 0.7245 - val_loss: 0.5590 - learning_rate: 1.5625e-05\n",
      "Epoch 165/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5630 - val_accuracy: 0.7249 - val_loss: 0.5589 - learning_rate: 1.5625e-05\n",
      "Epoch 166/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.5603 - val_accuracy: 0.7229 - val_loss: 0.5587 - learning_rate: 1.5625e-05\n",
      "Epoch 167/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5607 - val_accuracy: 0.7251 - val_loss: 0.5588 - learning_rate: 1.5625e-05\n",
      "Epoch 168/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.5604 - val_accuracy: 0.7232 - val_loss: 0.5586 - learning_rate: 1.5625e-05\n",
      "Epoch 169/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5569 - val_accuracy: 0.7235 - val_loss: 0.5587 - learning_rate: 1.5625e-05\n",
      "Epoch 170/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5666 - val_accuracy: 0.7235 - val_loss: 0.5584 - learning_rate: 1.5625e-05\n",
      "Epoch 171/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.5554 - val_accuracy: 0.7245 - val_loss: 0.5585 - learning_rate: 1.5625e-05\n",
      "Epoch 172/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5575 - val_accuracy: 0.7246 - val_loss: 0.5583 - learning_rate: 1.5625e-05\n",
      "Epoch 173/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5594 - val_accuracy: 0.7251 - val_loss: 0.5583 - learning_rate: 1.5625e-05\n",
      "Epoch 174/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.5574 - val_accuracy: 0.7245 - val_loss: 0.5584 - learning_rate: 1.5625e-05\n",
      "Epoch 175/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.5576 - val_accuracy: 0.7236 - val_loss: 0.5583 - learning_rate: 1.5625e-05\n",
      "Epoch 176/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5592 - val_accuracy: 0.7239 - val_loss: 0.5581 - learning_rate: 1.5625e-05\n",
      "Epoch 177/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5611 - val_accuracy: 0.7245 - val_loss: 0.5584 - learning_rate: 1.5625e-05\n",
      "Epoch 178/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.5525 - val_accuracy: 0.7245 - val_loss: 0.5583 - learning_rate: 1.5625e-05\n",
      "Epoch 179/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5623 - val_accuracy: 0.7246 - val_loss: 0.5582 - learning_rate: 1.5625e-05\n",
      "Epoch 180/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5603 - val_accuracy: 0.7248 - val_loss: 0.5579 - learning_rate: 1.5625e-05\n",
      "Epoch 181/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5615 - val_accuracy: 0.7230 - val_loss: 0.5582 - learning_rate: 1.5625e-05\n",
      "Epoch 182/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5571 - val_accuracy: 0.7238 - val_loss: 0.5582 - learning_rate: 1.5625e-05\n",
      "Epoch 183/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.5555 - val_accuracy: 0.7238 - val_loss: 0.5580 - learning_rate: 1.5625e-05\n",
      "Epoch 184/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5588 - val_accuracy: 0.7251 - val_loss: 0.5580 - learning_rate: 1.5625e-05\n",
      "Epoch 185/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5532 - val_accuracy: 0.7241 - val_loss: 0.5581 - learning_rate: 1.5625e-05\n",
      "Epoch 186/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5638 - val_accuracy: 0.7235 - val_loss: 0.5583 - learning_rate: 1.5625e-05\n",
      "Epoch 187/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5646 - val_accuracy: 0.7239 - val_loss: 0.5581 - learning_rate: 1.5625e-05\n",
      "Epoch 188/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5603 - val_accuracy: 0.7230 - val_loss: 0.5581 - learning_rate: 1.5625e-05\n",
      "Epoch 189/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.5597 - val_accuracy: 0.7235 - val_loss: 0.5579 - learning_rate: 7.8125e-06\n",
      "Epoch 190/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.5649 - val_accuracy: 0.7236 - val_loss: 0.5579 - learning_rate: 7.8125e-06\n",
      "Epoch 191/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5661 - val_accuracy: 0.7236 - val_loss: 0.5578 - learning_rate: 7.8125e-06\n",
      "Epoch 192/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5591 - val_accuracy: 0.7236 - val_loss: 0.5578 - learning_rate: 7.8125e-06\n",
      "Epoch 193/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5606 - val_accuracy: 0.7246 - val_loss: 0.5579 - learning_rate: 7.8125e-06\n",
      "Epoch 194/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5561 - val_accuracy: 0.7246 - val_loss: 0.5579 - learning_rate: 7.8125e-06\n",
      "Epoch 195/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5518 - val_accuracy: 0.7248 - val_loss: 0.5578 - learning_rate: 7.8125e-06\n",
      "Epoch 196/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5589 - val_accuracy: 0.7249 - val_loss: 0.5577 - learning_rate: 7.8125e-06\n",
      "Epoch 197/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5630 - val_accuracy: 0.7238 - val_loss: 0.5576 - learning_rate: 7.8125e-06\n",
      "Epoch 198/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5585 - val_accuracy: 0.7248 - val_loss: 0.5576 - learning_rate: 7.8125e-06\n",
      "Epoch 199/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.5640 - val_accuracy: 0.7246 - val_loss: 0.5577 - learning_rate: 7.8125e-06\n",
      "Epoch 200/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5645 - val_accuracy: 0.7248 - val_loss: 0.5576 - learning_rate: 7.8125e-06\n",
      "Epoch 201/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 0.5523 - val_accuracy: 0.7249 - val_loss: 0.5574 - learning_rate: 7.8125e-06\n",
      "Epoch 202/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5571 - val_accuracy: 0.7254 - val_loss: 0.5575 - learning_rate: 7.8125e-06\n",
      "Epoch 203/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.5604 - val_accuracy: 0.7249 - val_loss: 0.5573 - learning_rate: 7.8125e-06\n",
      "Epoch 204/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5588 - val_accuracy: 0.7239 - val_loss: 0.5572 - learning_rate: 7.8125e-06\n",
      "Epoch 205/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5543 - val_accuracy: 0.7249 - val_loss: 0.5571 - learning_rate: 7.8125e-06\n",
      "Epoch 206/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5564 - val_accuracy: 0.7248 - val_loss: 0.5571 - learning_rate: 7.8125e-06\n",
      "Epoch 207/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.5598 - val_accuracy: 0.7261 - val_loss: 0.5570 - learning_rate: 7.8125e-06\n",
      "Epoch 208/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.5530 - val_accuracy: 0.7246 - val_loss: 0.5571 - learning_rate: 7.8125e-06\n",
      "Epoch 209/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.5635 - val_accuracy: 0.7248 - val_loss: 0.5571 - learning_rate: 7.8125e-06\n",
      "Epoch 210/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5548 - val_accuracy: 0.7248 - val_loss: 0.5570 - learning_rate: 7.8125e-06\n",
      "Epoch 211/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.5552 - val_accuracy: 0.7255 - val_loss: 0.5569 - learning_rate: 7.8125e-06\n",
      "Epoch 212/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5621 - val_accuracy: 0.7249 - val_loss: 0.5569 - learning_rate: 7.8125e-06\n",
      "Epoch 213/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5540 - val_accuracy: 0.7249 - val_loss: 0.5569 - learning_rate: 7.8125e-06\n",
      "Epoch 214/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5556 - val_accuracy: 0.7257 - val_loss: 0.5570 - learning_rate: 7.8125e-06\n",
      "Epoch 215/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.5543 - val_accuracy: 0.7245 - val_loss: 0.5572 - learning_rate: 7.8125e-06\n",
      "Epoch 216/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5630 - val_accuracy: 0.7249 - val_loss: 0.5568 - learning_rate: 7.8125e-06\n",
      "Epoch 217/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5561 - val_accuracy: 0.7249 - val_loss: 0.5565 - learning_rate: 7.8125e-06\n",
      "Epoch 218/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5588 - val_accuracy: 0.7246 - val_loss: 0.5567 - learning_rate: 7.8125e-06\n",
      "Epoch 219/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5589 - val_accuracy: 0.7248 - val_loss: 0.5569 - learning_rate: 7.8125e-06\n",
      "Epoch 220/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.5566 - val_accuracy: 0.7242 - val_loss: 0.5570 - learning_rate: 7.8125e-06\n",
      "Epoch 221/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5568 - val_accuracy: 0.7249 - val_loss: 0.5572 - learning_rate: 7.8125e-06\n",
      "Epoch 222/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5568 - val_accuracy: 0.7251 - val_loss: 0.5569 - learning_rate: 7.8125e-06\n",
      "Epoch 223/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5554 - val_accuracy: 0.7254 - val_loss: 0.5567 - learning_rate: 7.8125e-06\n",
      "Epoch 224/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5562 - val_accuracy: 0.7249 - val_loss: 0.5566 - learning_rate: 7.8125e-06\n",
      "Epoch 225/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5542 - val_accuracy: 0.7251 - val_loss: 0.5566 - learning_rate: 7.8125e-06\n",
      "Epoch 226/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5615 - val_accuracy: 0.7248 - val_loss: 0.5565 - learning_rate: 3.9063e-06\n",
      "Epoch 227/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5581 - val_accuracy: 0.7251 - val_loss: 0.5566 - learning_rate: 3.9063e-06\n",
      "Epoch 228/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5577 - val_accuracy: 0.7248 - val_loss: 0.5566 - learning_rate: 3.9063e-06\n",
      "Epoch 229/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5585 - val_accuracy: 0.7248 - val_loss: 0.5567 - learning_rate: 3.9063e-06\n",
      "Epoch 230/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5564 - val_accuracy: 0.7246 - val_loss: 0.5567 - learning_rate: 3.9063e-06\n",
      "Epoch 231/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.5548 - val_accuracy: 0.7248 - val_loss: 0.5567 - learning_rate: 3.9063e-06\n",
      "Epoch 232/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5571 - val_accuracy: 0.7249 - val_loss: 0.5567 - learning_rate: 3.9063e-06\n",
      "Epoch 233/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7304 - loss: 0.5575 - val_accuracy: 0.7246 - val_loss: 0.5567 - learning_rate: 3.9063e-06\n",
      "Epoch 234/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5526 - val_accuracy: 0.7249 - val_loss: 0.5566 - learning_rate: 1.9531e-06\n",
      "Epoch 235/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5581 - val_accuracy: 0.7249 - val_loss: 0.5565 - learning_rate: 1.9531e-06\n",
      "Epoch 236/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5622 - val_accuracy: 0.7248 - val_loss: 0.5566 - learning_rate: 1.9531e-06\n",
      "Epoch 237/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5600 - val_accuracy: 0.7251 - val_loss: 0.5566 - learning_rate: 1.9531e-06\n",
      "Epoch 238/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5605 - val_accuracy: 0.7258 - val_loss: 0.5566 - learning_rate: 1.9531e-06\n",
      "Epoch 239/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.5605 - val_accuracy: 0.7262 - val_loss: 0.5565 - learning_rate: 1.9531e-06\n",
      "Epoch 240/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5608 - val_accuracy: 0.7261 - val_loss: 0.5565 - learning_rate: 1.9531e-06\n",
      "Epoch 241/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5532 - val_accuracy: 0.7251 - val_loss: 0.5565 - learning_rate: 1.9531e-06\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7273 - loss: 0.5540\n",
      "Final Loss: 0.5564727783203125, Final Accuracy: 0.724781334400177\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Early Stopping and ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "# Model Checkpointing\n",
    "model_checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n",
    "\n",
    "# Define the model with L2 regularization and dropout\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='leaky_relu', kernel_regularizer=l2(0.02), input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Dense(128, activation='leaky_relu', kernel_regularizer=l2(0.02)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Dense(64, activation='leaky_relu', kernel_regularizer=l2(0.02)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with AdamW optimizer\n",
    "model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=350,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Final Loss: {loss}, Final Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 2.9511 - val_accuracy: 0.7095 - val_loss: 1.2293 - learning_rate: 0.0010\n",
      "Epoch 2/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 1.0580 - val_accuracy: 0.7248 - val_loss: 0.7345 - learning_rate: 0.0010\n",
      "Epoch 3/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.7028 - val_accuracy: 0.7201 - val_loss: 0.6324 - learning_rate: 0.0010\n",
      "Epoch 4/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.6285 - val_accuracy: 0.7206 - val_loss: 0.6089 - learning_rate: 0.0010\n",
      "Epoch 5/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.6142 - val_accuracy: 0.7243 - val_loss: 0.6088 - learning_rate: 0.0010\n",
      "Epoch 6/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.6083 - val_accuracy: 0.7241 - val_loss: 0.6062 - learning_rate: 0.0010\n",
      "Epoch 7/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.6123 - val_accuracy: 0.7224 - val_loss: 0.6110 - learning_rate: 0.0010\n",
      "Epoch 8/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.6114 - val_accuracy: 0.7190 - val_loss: 0.6084 - learning_rate: 0.0010\n",
      "Epoch 9/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7200 - loss: 0.6064 - val_accuracy: 0.7165 - val_loss: 0.6117 - learning_rate: 0.0010\n",
      "Epoch 10/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.6042 - val_accuracy: 0.7204 - val_loss: 0.6031 - learning_rate: 0.0010\n",
      "Epoch 11/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.6060 - val_accuracy: 0.7182 - val_loss: 0.6105 - learning_rate: 0.0010\n",
      "Epoch 12/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.6040 - val_accuracy: 0.7179 - val_loss: 0.6033 - learning_rate: 0.0010\n",
      "Epoch 13/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.6072 - val_accuracy: 0.7245 - val_loss: 0.6005 - learning_rate: 0.0010\n",
      "Epoch 14/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.6039 - val_accuracy: 0.7210 - val_loss: 0.6064 - learning_rate: 0.0010\n",
      "Epoch 15/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.6145 - val_accuracy: 0.7153 - val_loss: 0.6080 - learning_rate: 0.0010\n",
      "Epoch 16/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.6026 - val_accuracy: 0.7227 - val_loss: 0.6015 - learning_rate: 0.0010\n",
      "Epoch 17/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.6052 - val_accuracy: 0.7222 - val_loss: 0.6072 - learning_rate: 0.0010\n",
      "Epoch 18/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.6018 - val_accuracy: 0.7181 - val_loss: 0.5984 - learning_rate: 0.0010\n",
      "Epoch 19/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.6013 - val_accuracy: 0.7242 - val_loss: 0.6042 - learning_rate: 0.0010\n",
      "Epoch 20/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.5997 - val_accuracy: 0.7236 - val_loss: 0.5960 - learning_rate: 0.0010\n",
      "Epoch 21/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.6048 - val_accuracy: 0.7195 - val_loss: 0.5964 - learning_rate: 0.0010\n",
      "Epoch 22/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6018 - val_accuracy: 0.7176 - val_loss: 0.5958 - learning_rate: 0.0010\n",
      "Epoch 23/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.5960 - val_accuracy: 0.7223 - val_loss: 0.5969 - learning_rate: 0.0010\n",
      "Epoch 24/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.5980 - val_accuracy: 0.7213 - val_loss: 0.5954 - learning_rate: 0.0010\n",
      "Epoch 25/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.5998 - val_accuracy: 0.7217 - val_loss: 0.5953 - learning_rate: 0.0010\n",
      "Epoch 26/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.6008 - val_accuracy: 0.7220 - val_loss: 0.5967 - learning_rate: 0.0010\n",
      "Epoch 27/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5952 - val_accuracy: 0.7249 - val_loss: 0.5959 - learning_rate: 0.0010\n",
      "Epoch 28/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.6000 - val_accuracy: 0.7257 - val_loss: 0.5923 - learning_rate: 0.0010\n",
      "Epoch 29/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.5953 - val_accuracy: 0.7198 - val_loss: 0.5950 - learning_rate: 0.0010\n",
      "Epoch 30/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.5980 - val_accuracy: 0.7207 - val_loss: 0.5956 - learning_rate: 0.0010\n",
      "Epoch 31/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.5940 - val_accuracy: 0.7176 - val_loss: 0.6026 - learning_rate: 0.0010\n",
      "Epoch 32/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.5959 - val_accuracy: 0.7194 - val_loss: 0.5926 - learning_rate: 0.0010\n",
      "Epoch 33/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5983 - val_accuracy: 0.7188 - val_loss: 0.5993 - learning_rate: 0.0010\n",
      "Epoch 34/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.5939 - val_accuracy: 0.7178 - val_loss: 0.5967 - learning_rate: 0.0010\n",
      "Epoch 35/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5978 - val_accuracy: 0.7230 - val_loss: 0.5926 - learning_rate: 0.0010\n",
      "Epoch 36/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5931 - val_accuracy: 0.7200 - val_loss: 0.5935 - learning_rate: 0.0010\n",
      "Epoch 37/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.5853 - val_accuracy: 0.7232 - val_loss: 0.5860 - learning_rate: 5.0000e-04\n",
      "Epoch 38/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5797 - val_accuracy: 0.7233 - val_loss: 0.5786 - learning_rate: 5.0000e-04\n",
      "Epoch 39/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.5800 - val_accuracy: 0.7236 - val_loss: 0.5777 - learning_rate: 5.0000e-04\n",
      "Epoch 40/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5807 - val_accuracy: 0.7246 - val_loss: 0.5780 - learning_rate: 5.0000e-04\n",
      "Epoch 41/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5827 - val_accuracy: 0.7236 - val_loss: 0.5775 - learning_rate: 5.0000e-04\n",
      "Epoch 42/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5777 - val_accuracy: 0.7219 - val_loss: 0.5778 - learning_rate: 5.0000e-04\n",
      "Epoch 43/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5774 - val_accuracy: 0.7245 - val_loss: 0.5793 - learning_rate: 5.0000e-04\n",
      "Epoch 44/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.5783 - val_accuracy: 0.7248 - val_loss: 0.5767 - learning_rate: 5.0000e-04\n",
      "Epoch 45/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5748 - val_accuracy: 0.7232 - val_loss: 0.5767 - learning_rate: 5.0000e-04\n",
      "Epoch 46/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5800 - val_accuracy: 0.7242 - val_loss: 0.5754 - learning_rate: 5.0000e-04\n",
      "Epoch 47/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5804 - val_accuracy: 0.7222 - val_loss: 0.5767 - learning_rate: 5.0000e-04\n",
      "Epoch 48/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5786 - val_accuracy: 0.7254 - val_loss: 0.5749 - learning_rate: 5.0000e-04\n",
      "Epoch 49/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.5841 - val_accuracy: 0.7222 - val_loss: 0.5754 - learning_rate: 5.0000e-04\n",
      "Epoch 50/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5767 - val_accuracy: 0.7185 - val_loss: 0.5829 - learning_rate: 5.0000e-04\n",
      "Epoch 51/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.5792 - val_accuracy: 0.7243 - val_loss: 0.5779 - learning_rate: 5.0000e-04\n",
      "Epoch 52/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5764 - val_accuracy: 0.7259 - val_loss: 0.5757 - learning_rate: 5.0000e-04\n",
      "Epoch 53/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5799 - val_accuracy: 0.7238 - val_loss: 0.5753 - learning_rate: 5.0000e-04\n",
      "Epoch 54/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5755 - val_accuracy: 0.7254 - val_loss: 0.5755 - learning_rate: 5.0000e-04\n",
      "Epoch 55/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.5788 - val_accuracy: 0.7273 - val_loss: 0.5741 - learning_rate: 5.0000e-04\n",
      "Epoch 56/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5778 - val_accuracy: 0.7245 - val_loss: 0.5767 - learning_rate: 5.0000e-04\n",
      "Epoch 57/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.5792 - val_accuracy: 0.7261 - val_loss: 0.5770 - learning_rate: 5.0000e-04\n",
      "Epoch 58/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5802 - val_accuracy: 0.7278 - val_loss: 0.5770 - learning_rate: 5.0000e-04\n",
      "Epoch 59/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5742 - val_accuracy: 0.7255 - val_loss: 0.5749 - learning_rate: 5.0000e-04\n",
      "Epoch 60/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5765 - val_accuracy: 0.7286 - val_loss: 0.5738 - learning_rate: 5.0000e-04\n",
      "Epoch 61/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.5773 - val_accuracy: 0.7230 - val_loss: 0.5747 - learning_rate: 5.0000e-04\n",
      "Epoch 62/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.5745 - val_accuracy: 0.7246 - val_loss: 0.5761 - learning_rate: 5.0000e-04\n",
      "Epoch 63/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5752 - val_accuracy: 0.7271 - val_loss: 0.5759 - learning_rate: 5.0000e-04\n",
      "Epoch 64/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5734 - val_accuracy: 0.7268 - val_loss: 0.5760 - learning_rate: 5.0000e-04\n",
      "Epoch 65/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.5821 - val_accuracy: 0.7257 - val_loss: 0.5745 - learning_rate: 5.0000e-04\n",
      "Epoch 66/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5787 - val_accuracy: 0.7264 - val_loss: 0.5746 - learning_rate: 5.0000e-04\n",
      "Epoch 67/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.5814 - val_accuracy: 0.7245 - val_loss: 0.5741 - learning_rate: 5.0000e-04\n",
      "Epoch 68/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5799 - val_accuracy: 0.7277 - val_loss: 0.5763 - learning_rate: 5.0000e-04\n",
      "Epoch 69/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5756 - val_accuracy: 0.7265 - val_loss: 0.5706 - learning_rate: 2.5000e-04\n",
      "Epoch 70/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.5691 - val_accuracy: 0.7265 - val_loss: 0.5693 - learning_rate: 2.5000e-04\n",
      "Epoch 71/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.5681 - val_accuracy: 0.7251 - val_loss: 0.5705 - learning_rate: 2.5000e-04\n",
      "Epoch 72/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.5720 - val_accuracy: 0.7219 - val_loss: 0.5688 - learning_rate: 2.5000e-04\n",
      "Epoch 73/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.5679 - val_accuracy: 0.7264 - val_loss: 0.5668 - learning_rate: 2.5000e-04\n",
      "Epoch 74/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5683 - val_accuracy: 0.7262 - val_loss: 0.5665 - learning_rate: 2.5000e-04\n",
      "Epoch 75/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.5679 - val_accuracy: 0.7274 - val_loss: 0.5682 - learning_rate: 2.5000e-04\n",
      "Epoch 76/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5665 - val_accuracy: 0.7262 - val_loss: 0.5681 - learning_rate: 2.5000e-04\n",
      "Epoch 77/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5701 - val_accuracy: 0.7251 - val_loss: 0.5685 - learning_rate: 2.5000e-04\n",
      "Epoch 78/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5709 - val_accuracy: 0.7286 - val_loss: 0.5672 - learning_rate: 2.5000e-04\n",
      "Epoch 79/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5666 - val_accuracy: 0.7236 - val_loss: 0.5676 - learning_rate: 2.5000e-04\n",
      "Epoch 80/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5689 - val_accuracy: 0.7245 - val_loss: 0.5670 - learning_rate: 2.5000e-04\n",
      "Epoch 81/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5705 - val_accuracy: 0.7219 - val_loss: 0.5707 - learning_rate: 2.5000e-04\n",
      "Epoch 82/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5652 - val_accuracy: 0.7274 - val_loss: 0.5678 - learning_rate: 2.5000e-04\n",
      "Epoch 83/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5645 - val_accuracy: 0.7264 - val_loss: 0.5647 - learning_rate: 1.2500e-04\n",
      "Epoch 84/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5677 - val_accuracy: 0.7316 - val_loss: 0.5630 - learning_rate: 1.2500e-04\n",
      "Epoch 85/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.5674 - val_accuracy: 0.7268 - val_loss: 0.5628 - learning_rate: 1.2500e-04\n",
      "Epoch 86/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5627 - val_accuracy: 0.7270 - val_loss: 0.5622 - learning_rate: 1.2500e-04\n",
      "Epoch 87/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5634 - val_accuracy: 0.7284 - val_loss: 0.5616 - learning_rate: 1.2500e-04\n",
      "Epoch 88/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5594 - val_accuracy: 0.7300 - val_loss: 0.5616 - learning_rate: 1.2500e-04\n",
      "Epoch 89/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5662 - val_accuracy: 0.7313 - val_loss: 0.5617 - learning_rate: 1.2500e-04\n",
      "Epoch 90/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5602 - val_accuracy: 0.7271 - val_loss: 0.5606 - learning_rate: 1.2500e-04\n",
      "Epoch 91/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5648 - val_accuracy: 0.7268 - val_loss: 0.5611 - learning_rate: 1.2500e-04\n",
      "Epoch 92/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5637 - val_accuracy: 0.7321 - val_loss: 0.5610 - learning_rate: 1.2500e-04\n",
      "Epoch 93/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5643 - val_accuracy: 0.7292 - val_loss: 0.5615 - learning_rate: 1.2500e-04\n",
      "Epoch 94/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.5626 - val_accuracy: 0.7293 - val_loss: 0.5605 - learning_rate: 1.2500e-04\n",
      "Epoch 95/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5623 - val_accuracy: 0.7299 - val_loss: 0.5624 - learning_rate: 1.2500e-04\n",
      "Epoch 96/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.5618 - val_accuracy: 0.7268 - val_loss: 0.5606 - learning_rate: 1.2500e-04\n",
      "Epoch 97/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5628 - val_accuracy: 0.7280 - val_loss: 0.5608 - learning_rate: 1.2500e-04\n",
      "Epoch 98/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5587 - val_accuracy: 0.7261 - val_loss: 0.5607 - learning_rate: 1.2500e-04\n",
      "Epoch 99/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.5606 - val_accuracy: 0.7308 - val_loss: 0.5600 - learning_rate: 1.2500e-04\n",
      "Epoch 100/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5581 - val_accuracy: 0.7283 - val_loss: 0.5601 - learning_rate: 1.2500e-04\n",
      "Epoch 101/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5598 - val_accuracy: 0.7262 - val_loss: 0.5613 - learning_rate: 1.2500e-04\n",
      "Epoch 102/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.5597 - val_accuracy: 0.7293 - val_loss: 0.5601 - learning_rate: 1.2500e-04\n",
      "Epoch 103/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5568 - val_accuracy: 0.7259 - val_loss: 0.5615 - learning_rate: 1.2500e-04\n",
      "Epoch 104/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5511 - val_accuracy: 0.7274 - val_loss: 0.5605 - learning_rate: 1.2500e-04\n",
      "Epoch 105/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5632 - val_accuracy: 0.7264 - val_loss: 0.5614 - learning_rate: 1.2500e-04\n",
      "Epoch 106/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5586 - val_accuracy: 0.7290 - val_loss: 0.5615 - learning_rate: 1.2500e-04\n",
      "Epoch 107/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5632 - val_accuracy: 0.7290 - val_loss: 0.5602 - learning_rate: 1.2500e-04\n",
      "Epoch 108/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5593 - val_accuracy: 0.7296 - val_loss: 0.5602 - learning_rate: 6.2500e-05\n",
      "Epoch 109/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.5630 - val_accuracy: 0.7305 - val_loss: 0.5590 - learning_rate: 6.2500e-05\n",
      "Epoch 110/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.5621 - val_accuracy: 0.7280 - val_loss: 0.5593 - learning_rate: 6.2500e-05\n",
      "Epoch 111/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5557 - val_accuracy: 0.7280 - val_loss: 0.5587 - learning_rate: 6.2500e-05\n",
      "Epoch 112/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5621 - val_accuracy: 0.7308 - val_loss: 0.5583 - learning_rate: 6.2500e-05\n",
      "Epoch 113/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.5535 - val_accuracy: 0.7303 - val_loss: 0.5588 - learning_rate: 6.2500e-05\n",
      "Epoch 114/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5550 - val_accuracy: 0.7293 - val_loss: 0.5581 - learning_rate: 6.2500e-05\n",
      "Epoch 115/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5607 - val_accuracy: 0.7292 - val_loss: 0.5584 - learning_rate: 6.2500e-05\n",
      "Epoch 116/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5582 - val_accuracy: 0.7262 - val_loss: 0.5581 - learning_rate: 6.2500e-05\n",
      "Epoch 117/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5554 - val_accuracy: 0.7280 - val_loss: 0.5582 - learning_rate: 6.2500e-05\n",
      "Epoch 118/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.5572 - val_accuracy: 0.7280 - val_loss: 0.5580 - learning_rate: 6.2500e-05\n",
      "Epoch 119/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5580 - val_accuracy: 0.7310 - val_loss: 0.5585 - learning_rate: 6.2500e-05\n",
      "Epoch 120/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5558 - val_accuracy: 0.7303 - val_loss: 0.5581 - learning_rate: 6.2500e-05\n",
      "Epoch 121/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5525 - val_accuracy: 0.7313 - val_loss: 0.5578 - learning_rate: 6.2500e-05\n",
      "Epoch 122/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5541 - val_accuracy: 0.7277 - val_loss: 0.5584 - learning_rate: 6.2500e-05\n",
      "Epoch 123/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 0.5540 - val_accuracy: 0.7277 - val_loss: 0.5584 - learning_rate: 6.2500e-05\n",
      "Epoch 124/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5589 - val_accuracy: 0.7310 - val_loss: 0.5575 - learning_rate: 6.2500e-05\n",
      "Epoch 125/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5638 - val_accuracy: 0.7309 - val_loss: 0.5576 - learning_rate: 6.2500e-05\n",
      "Epoch 126/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.5596 - val_accuracy: 0.7310 - val_loss: 0.5580 - learning_rate: 6.2500e-05\n",
      "Epoch 127/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.5530 - val_accuracy: 0.7302 - val_loss: 0.5576 - learning_rate: 6.2500e-05\n",
      "Epoch 128/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5528 - val_accuracy: 0.7262 - val_loss: 0.5581 - learning_rate: 6.2500e-05\n",
      "Epoch 129/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.5579 - val_accuracy: 0.7302 - val_loss: 0.5576 - learning_rate: 6.2500e-05\n",
      "Epoch 130/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5575 - val_accuracy: 0.7306 - val_loss: 0.5569 - learning_rate: 6.2500e-05\n",
      "Epoch 131/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5560 - val_accuracy: 0.7289 - val_loss: 0.5573 - learning_rate: 6.2500e-05\n",
      "Epoch 132/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.5605 - val_accuracy: 0.7303 - val_loss: 0.5583 - learning_rate: 6.2500e-05\n",
      "Epoch 133/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.5572 - val_accuracy: 0.7300 - val_loss: 0.5572 - learning_rate: 6.2500e-05\n",
      "Epoch 134/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.5493 - val_accuracy: 0.7312 - val_loss: 0.5574 - learning_rate: 6.2500e-05\n",
      "Epoch 135/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5553 - val_accuracy: 0.7321 - val_loss: 0.5569 - learning_rate: 6.2500e-05\n",
      "Epoch 136/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.5567 - val_accuracy: 0.7281 - val_loss: 0.5576 - learning_rate: 6.2500e-05\n",
      "Epoch 137/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.5527 - val_accuracy: 0.7310 - val_loss: 0.5577 - learning_rate: 6.2500e-05\n",
      "Epoch 138/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5535 - val_accuracy: 0.7290 - val_loss: 0.5573 - learning_rate: 6.2500e-05\n",
      "Epoch 139/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5582 - val_accuracy: 0.7306 - val_loss: 0.5569 - learning_rate: 3.1250e-05\n",
      "Epoch 140/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5530 - val_accuracy: 0.7276 - val_loss: 0.5568 - learning_rate: 3.1250e-05\n",
      "Epoch 141/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5547 - val_accuracy: 0.7270 - val_loss: 0.5568 - learning_rate: 3.1250e-05\n",
      "Epoch 142/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.5594 - val_accuracy: 0.7297 - val_loss: 0.5563 - learning_rate: 3.1250e-05\n",
      "Epoch 143/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5543 - val_accuracy: 0.7300 - val_loss: 0.5564 - learning_rate: 3.1250e-05\n",
      "Epoch 144/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.5563 - val_accuracy: 0.7270 - val_loss: 0.5559 - learning_rate: 3.1250e-05\n",
      "Epoch 145/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5558 - val_accuracy: 0.7308 - val_loss: 0.5564 - learning_rate: 3.1250e-05\n",
      "Epoch 146/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5579 - val_accuracy: 0.7299 - val_loss: 0.5564 - learning_rate: 3.1250e-05\n",
      "Epoch 147/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7387 - loss: 0.5500 - val_accuracy: 0.7300 - val_loss: 0.5565 - learning_rate: 3.1250e-05\n",
      "Epoch 148/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.5587 - val_accuracy: 0.7309 - val_loss: 0.5564 - learning_rate: 3.1250e-05\n",
      "Epoch 149/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5534 - val_accuracy: 0.7305 - val_loss: 0.5563 - learning_rate: 3.1250e-05\n",
      "Epoch 150/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5529 - val_accuracy: 0.7305 - val_loss: 0.5566 - learning_rate: 3.1250e-05\n",
      "Epoch 151/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.5579 - val_accuracy: 0.7302 - val_loss: 0.5565 - learning_rate: 3.1250e-05\n",
      "Epoch 152/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5584 - val_accuracy: 0.7310 - val_loss: 0.5555 - learning_rate: 3.1250e-05\n",
      "Epoch 153/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5582 - val_accuracy: 0.7258 - val_loss: 0.5561 - learning_rate: 3.1250e-05\n",
      "Epoch 154/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5563 - val_accuracy: 0.7259 - val_loss: 0.5561 - learning_rate: 3.1250e-05\n",
      "Epoch 155/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5522 - val_accuracy: 0.7262 - val_loss: 0.5565 - learning_rate: 3.1250e-05\n",
      "Epoch 156/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.5587 - val_accuracy: 0.7296 - val_loss: 0.5560 - learning_rate: 3.1250e-05\n",
      "Epoch 157/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5583 - val_accuracy: 0.7293 - val_loss: 0.5557 - learning_rate: 3.1250e-05\n",
      "Epoch 158/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.5525 - val_accuracy: 0.7284 - val_loss: 0.5557 - learning_rate: 3.1250e-05\n",
      "Epoch 159/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5517 - val_accuracy: 0.7287 - val_loss: 0.5558 - learning_rate: 3.1250e-05\n",
      "Epoch 160/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.5518 - val_accuracy: 0.7306 - val_loss: 0.5553 - learning_rate: 3.1250e-05\n",
      "Epoch 161/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5520 - val_accuracy: 0.7299 - val_loss: 0.5559 - learning_rate: 3.1250e-05\n",
      "Epoch 162/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.5517 - val_accuracy: 0.7308 - val_loss: 0.5556 - learning_rate: 3.1250e-05\n",
      "Epoch 163/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5563 - val_accuracy: 0.7308 - val_loss: 0.5555 - learning_rate: 3.1250e-05\n",
      "Epoch 164/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5585 - val_accuracy: 0.7303 - val_loss: 0.5557 - learning_rate: 3.1250e-05\n",
      "Epoch 165/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5546 - val_accuracy: 0.7308 - val_loss: 0.5555 - learning_rate: 3.1250e-05\n",
      "Epoch 166/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5554 - val_accuracy: 0.7300 - val_loss: 0.5553 - learning_rate: 3.1250e-05\n",
      "Epoch 167/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5553 - val_accuracy: 0.7309 - val_loss: 0.5553 - learning_rate: 3.1250e-05\n",
      "Epoch 168/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5527 - val_accuracy: 0.7310 - val_loss: 0.5552 - learning_rate: 3.1250e-05\n",
      "Epoch 169/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5583 - val_accuracy: 0.7312 - val_loss: 0.5555 - learning_rate: 3.1250e-05\n",
      "Epoch 170/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.5615 - val_accuracy: 0.7297 - val_loss: 0.5556 - learning_rate: 3.1250e-05\n",
      "Epoch 171/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5565 - val_accuracy: 0.7300 - val_loss: 0.5552 - learning_rate: 3.1250e-05\n",
      "Epoch 172/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.5497 - val_accuracy: 0.7305 - val_loss: 0.5550 - learning_rate: 3.1250e-05\n",
      "Epoch 173/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5505 - val_accuracy: 0.7280 - val_loss: 0.5557 - learning_rate: 3.1250e-05\n",
      "Epoch 174/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5540 - val_accuracy: 0.7310 - val_loss: 0.5551 - learning_rate: 3.1250e-05\n",
      "Epoch 175/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.5581 - val_accuracy: 0.7302 - val_loss: 0.5550 - learning_rate: 3.1250e-05\n",
      "Epoch 176/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.5543 - val_accuracy: 0.7308 - val_loss: 0.5551 - learning_rate: 3.1250e-05\n",
      "Epoch 177/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5540 - val_accuracy: 0.7293 - val_loss: 0.5556 - learning_rate: 3.1250e-05\n",
      "Epoch 178/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.5579 - val_accuracy: 0.7296 - val_loss: 0.5549 - learning_rate: 3.1250e-05\n",
      "Epoch 179/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5571 - val_accuracy: 0.7292 - val_loss: 0.5549 - learning_rate: 3.1250e-05\n",
      "Epoch 180/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.5509 - val_accuracy: 0.7313 - val_loss: 0.5551 - learning_rate: 3.1250e-05\n",
      "Epoch 181/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5552 - val_accuracy: 0.7306 - val_loss: 0.5553 - learning_rate: 3.1250e-05\n",
      "Epoch 182/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5531 - val_accuracy: 0.7302 - val_loss: 0.5552 - learning_rate: 3.1250e-05\n",
      "Epoch 183/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.5497 - val_accuracy: 0.7292 - val_loss: 0.5557 - learning_rate: 3.1250e-05\n",
      "Epoch 184/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7304 - loss: 0.5548 - val_accuracy: 0.7303 - val_loss: 0.5551 - learning_rate: 3.1250e-05\n",
      "Epoch 185/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5539 - val_accuracy: 0.7310 - val_loss: 0.5554 - learning_rate: 3.1250e-05\n",
      "Epoch 186/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.5489 - val_accuracy: 0.7313 - val_loss: 0.5546 - learning_rate: 3.1250e-05\n",
      "Epoch 187/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5529 - val_accuracy: 0.7297 - val_loss: 0.5553 - learning_rate: 3.1250e-05\n",
      "Epoch 188/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5545 - val_accuracy: 0.7316 - val_loss: 0.5551 - learning_rate: 3.1250e-05\n",
      "Epoch 189/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.5542 - val_accuracy: 0.7300 - val_loss: 0.5549 - learning_rate: 3.1250e-05\n",
      "Epoch 190/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.5519 - val_accuracy: 0.7306 - val_loss: 0.5554 - learning_rate: 3.1250e-05\n",
      "Epoch 191/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.5566 - val_accuracy: 0.7316 - val_loss: 0.5554 - learning_rate: 3.1250e-05\n",
      "Epoch 192/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5528 - val_accuracy: 0.7306 - val_loss: 0.5548 - learning_rate: 3.1250e-05\n",
      "Epoch 193/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5504 - val_accuracy: 0.7302 - val_loss: 0.5555 - learning_rate: 3.1250e-05\n",
      "Epoch 194/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7382 - loss: 0.5484 - val_accuracy: 0.7306 - val_loss: 0.5552 - learning_rate: 3.1250e-05\n",
      "Epoch 195/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7304 - loss: 0.5512 - val_accuracy: 0.7315 - val_loss: 0.5548 - learning_rate: 1.5625e-05\n",
      "Epoch 196/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5550 - val_accuracy: 0.7312 - val_loss: 0.5549 - learning_rate: 1.5625e-05\n",
      "Epoch 197/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.5488 - val_accuracy: 0.7310 - val_loss: 0.5549 - learning_rate: 1.5625e-05\n",
      "Epoch 198/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5502 - val_accuracy: 0.7309 - val_loss: 0.5547 - learning_rate: 1.5625e-05\n",
      "Epoch 199/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5484 - val_accuracy: 0.7309 - val_loss: 0.5547 - learning_rate: 1.5625e-05\n",
      "Epoch 200/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7356 - loss: 0.5512 - val_accuracy: 0.7310 - val_loss: 0.5547 - learning_rate: 1.5625e-05\n",
      "Epoch 201/350\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7366 - loss: 0.5481 - val_accuracy: 0.7303 - val_loss: 0.5548 - learning_rate: 1.5625e-05\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.7308 - loss: 0.5531\n",
      "Final Loss: 0.5546199679374695, Final Accuracy: 0.7313411235809326\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Implement Early Stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "\n",
    "# Reduce learning rate when performance stops improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=8, min_lr=0.00001)\n",
    "\n",
    "# Modify the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with a different optimizer\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model with the new epochs and callbacks\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=350,  # Increased epochs for better convergence\n",
    "    batch_size=64,  # Adjust batch size for stability\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Final Loss: {loss}, Final Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
